Необходимо реализовать простую нейронную сеть(не обязательно сверточную(!)) и обучить ее на датасете
- Каждый слой прописывается руками, перекладыванием матричек/тензоров из состояния А в состояние Б
- Возможные слои/классы, которые вам понадобятся для успешного закрытия лабы: Linear/Dense, Dropout, Conv2d, MaxPool2D, ReLU, Softmax, Flatten, Adam.
- В классе не должно быть волшебных истинно торчовских методов (т.е. ваш класс, который выглядит типа такого:
```
class Linear:
   def __init__(...):
        lin = nn.Linear(...)
```
не принимается. Все делаем ручками.
- Выводим графики нескольких моделей, с экспериментами (разный порядок слоев, разные входные/выходные параметры), выбираем свою лучшую модельку
- dataset https://www.kaggle.com/datasets/hojjatk/mnist-dataset
